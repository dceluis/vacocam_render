{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: line_profiler[ipython] in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (4.0.3)\n",
      "Requirement already satisfied: ipython==8.5.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (8.5.0)\n",
      "Requirement already satisfied: ffmpeg-python in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: imutils==0.5.4 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (0.5.4)\n",
      "Requirement already satisfied: sahi in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (0.11.15)\n",
      "Requirement already satisfied: scikit-learn in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: supervision in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (0.18.0)\n",
      "Requirement already satisfied: anthropic in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (0.21.3)\n",
      "Requirement already satisfied: ipywidgets in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (3.0.43)\n",
      "Requirement already satisfied: backcall in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (5.14.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (4.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (2.17.2)\n",
      "Requirement already satisfied: pickleshare in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (0.7.5)\n",
      "Requirement already satisfied: decorator in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipython==8.5.0) (5.1.1)\n",
      "Requirement already satisfied: future in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ffmpeg-python) (0.18.3)\n",
      "Requirement already satisfied: opencv-python<=4.8 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (4.7.0.72)\n",
      "Requirement already satisfied: pybboxes==0.1.6 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (0.1.6)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (10.2.0)\n",
      "Requirement already satisfied: pyyaml in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (6.0.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (2.0.2)\n",
      "Requirement already satisfied: fire in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (0.5.0)\n",
      "Requirement already satisfied: requests in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (2.31.0)\n",
      "Requirement already satisfied: click in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (8.1.7)\n",
      "Requirement already satisfied: terminaltables in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (3.1.10)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from sahi) (4.66.1)\n",
      "Requirement already satisfied: numpy in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from pybboxes==0.1.6->sahi) (1.26.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from supervision) (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from supervision) (3.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (2.6.0)\n",
      "Requirement already satisfied: sniffio in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (0.26.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (0.15.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.2)\n",
      "Requirement already satisfied: certifi in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->anthropic) (2023.11.17)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from jedi>=0.16->ipython==8.5.0) (0.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (6.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (4.47.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from pexpect>4.3->ipython==8.5.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython==8.5.0) (0.2.13)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from tokenizers>=0.13.0->anthropic) (0.22.2)\n",
      "Requirement already satisfied: six in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from fire->sahi) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from fire->sahi) (2.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from requests->sahi) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from requests->sahi) (3.3.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from stack-data->ipython==8.5.0) (2.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from stack-data->ipython==8.5.0) (2.0.1)\n",
      "Requirement already satisfied: pure-eval in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from stack-data->ipython==8.5.0) (0.2.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.12.2)\n",
      "Requirement already satisfied: filelock in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/luis/workspace/vacocam_render/venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.6.0->supervision) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"line_profiler[ipython]\" ipython==8.5.0 ffmpeg-python imutils==0.5.4 sahi scikit-learn supervision anthropic ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This experiment depends on specific files.\n",
    "video_path = \"/home/luis/workspace/vacocam_render/source/prerender.mp4\"\n",
    "detections_path = \"/home/luis/workspace/vacocam_render/experiments/vacocam/2024_04_02-2_claude3_5sec/source/track/prerender_detections_declustered.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are correct.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "md5 = hashlib.md5()\n",
    "\n",
    "with open(video_path, \"rb\") as f:\n",
    "    for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "        md5.update(chunk)\n",
    "\n",
    "assert md5.hexdigest() == \"6d30279ea8ab9754c748d5752d97a027\", \"The video file is not the correct one.\"\n",
    "\n",
    "md5 = hashlib.md5()\n",
    "with open(detections_path, \"rb\") as f:\n",
    "    for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "        md5.update(chunk)\n",
    "\n",
    "assert md5.hexdigest() == \"0631148b034011bb4fd463ee9ab9323e\", \"The detections file is not the correct one.\"\n",
    "\n",
    "print(\"All files are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, generate a presentation for every section in our video. This includes loading the cleaned up ball detections for the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 112300 detections from /home/luis/workspace/vacocam_render/experiments/vacocam/2024_04_02-2_claude3_5sec/source/track/prerender_detections_declustered.npy\n"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from detections import load_detections, Detections\n",
    "\n",
    "_, detections = load_detections(detections_path)\n",
    "\n",
    "seconds = 5\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "\n",
    "framerate = video_info.fps\n",
    "total_frames = video_info.total_frames or 0\n",
    "\n",
    "frame_indices = [(i * seconds * framerate, (i + 1) * seconds * framerate) for i in range(int(total_frames / (seconds * framerate)))]\n",
    "if frame_indices[-1][1] != total_frames:\n",
    "    frame_indices.append((frame_indices[-1][1], total_frames))\n",
    "\n",
    "def make_video_section(start, end):\n",
    "    dets = detections[start:end]\n",
    "    # find a frame in the middle of the section, but provided it has detections\n",
    "    mid = int((start + end) / 2)\n",
    "\n",
    "    while len(detections[mid]) == 0:\n",
    "        mid += 1\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid)\n",
    "    ret, sample = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        raise Exception(\"Error reading video\")\n",
    "\n",
    "    sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cap.release()\n",
    "    return (dets, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VacomCam] Done finding overlaps\n",
      "[VacomCam] Found 20 overlaps\n"
     ]
    }
   ],
   "source": [
    "# cluster detections and find overlaps\n",
    "\n",
    "from tracking import cluster_detections, get_artifact_id\n",
    "\n",
    "overlaps = {}\n",
    "\n",
    "for start, end in frame_indices:\n",
    "    section_detections = detections[start:end]\n",
    "    clustered_detections: dict[int, list[Detections]] = cluster_detections(section_detections, preset=\"play\")\n",
    "\n",
    "    clustered_detections_minus_noise: dict[int, list[Detections]] = { key: detections for key, detections in clustered_detections.items() if key != -1 }\n",
    "\n",
    "    # find clusters start and ends\n",
    "    start_ends: dict[int, tuple[int, int]] = { key: (0, 0) for key in clustered_detections_minus_noise.keys() }\n",
    "\n",
    "    for key, c_detections in clustered_detections_minus_noise.items():\n",
    "        # find start of the cluster, meaning the index of the first detection that is not empty. (len(detection) > 0)\n",
    "        cluster_start = 0\n",
    "        for i, detection in enumerate(c_detections):\n",
    "            if len(detection) > 0:\n",
    "                cluster_start = i\n",
    "                break\n",
    "        # find end of the cluster, meaning the index of the last detection that is not empty. (len(detection) > 0)\n",
    "        cluster_end = 0\n",
    "        for i, detection in enumerate(reversed(c_detections)):\n",
    "            if len(detection) > 0:\n",
    "                cluster_end = len(c_detections) - i\n",
    "                break\n",
    "        start_ends[key] = (cluster_start, cluster_end)\n",
    "    \n",
    "    # now find any overlapping clusters\n",
    "    overlapping_clusters = {}\n",
    "\n",
    "    for key1, (start1, end1) in start_ends.items():\n",
    "        for key2, (start2, end2) in start_ends.items():\n",
    "            if key1 != key2 and start1 < end2 and end1 > start2:\n",
    "                overlap = min(end1, end2) - max(start1, start2)\n",
    "\n",
    "                if (key1, key2) in overlapping_clusters or (key2, key1) in overlapping_clusters:\n",
    "                    continue\n",
    "                if overlap < min(end1 - start1, end2 - start2) * 0.5:\n",
    "                    continue\n",
    "                if end1 - start1 < 15 or end2 - start2 < 15 or overlap < 15:\n",
    "                    continue\n",
    "\n",
    "                overlapping_clusters[(key1, key2)] = {\n",
    "                    \"overlap\": min(end1, end2) - max(start1, start2),\n",
    "                    \"clusters\": {\n",
    "                        key1: clustered_detections_minus_noise[key1],\n",
    "                        key2: clustered_detections_minus_noise[key2]\n",
    "                    },\n",
    "                    \"bounds\": {\n",
    "                        key1: (start + start1, start + end1),\n",
    "                        key2: (start + start2, start + end2)\n",
    "                    },\n",
    "                }\n",
    "\n",
    "\n",
    "    if len(overlapping_clusters) > 0:\n",
    "        overlaps[(start, end)] = overlapping_clusters\n",
    "\n",
    "print(\"[VacomCam] Done finding overlaps\")\n",
    "print(\"[VacomCam] Found {} overlaps\".format(sum([len(value) for value in overlaps.values()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29:15 - 29:20\n",
      "\t0 - 1 (134 frames overlap)\n",
      "\t\t29:15 - 29:19\n",
      "No cluster angles for cluster  1\n",
      "\t0 - 2 (18 frames overlap)\n",
      "\t\t29:15 - 29:19\n",
      "No cluster angles for cluster  2\n",
      "\t1 - 2 (18 frames overlap)\n",
      "\t\t29:15 - 29:19\n",
      "No cluster angles for cluster  1\n",
      "No cluster angles for cluster  2\n",
      "49:0 - 49:5\n",
      "\t1 - 2 (103 frames overlap)\n",
      "\t\t49:1 - 49:5\n",
      "11:45 - 11:50\n",
      "\t0 - 1 (34 frames overlap)\n",
      "\t\t11:45 - 11:49\n",
      "\t1 - 2 (67 frames overlap)\n",
      "\t\t11:45 - 11:50\n",
      "5:40 - 5:45\n",
      "\t0 - 1 (68 frames overlap)\n",
      "\t\t5:40 - 5:42\n",
      "9:30 - 9:35\n",
      "\t1 - 2 (64 frames overlap)\n",
      "\t\t9:31 - 9:35\n",
      "57:35 - 57:40\n",
      "\t5 - 6 (60 frames overlap)\n",
      "\t\t57:37 - 57:40\n",
      "5:35 - 5:40\n",
      "\t0 - 1 (54 frames overlap)\n",
      "\t\t5:35 - 5:37\n",
      "35:35 - 35:40\n",
      "\t1 - 2 (54 frames overlap)\n",
      "\t\t35:35 - 35:40\n",
      "No cluster angles for cluster  2\n",
      "16:10 - 16:15\n",
      "\t1 - 2 (53 frames overlap)\n",
      "\t\t16:12 - 16:15\n",
      "12:55 - 13:0\n",
      "\t0 - 1 (52 frames overlap)\n",
      "\t\t12:55 - 12:57\n",
      "No cluster angles for cluster  0\n",
      "20:25 - 20:30\n",
      "\t0 - 1 (46 frames overlap)\n",
      "\t\t20:27 - 20:29\n",
      "6:15 - 6:20\n",
      "\t0 - 1 (45 frames overlap)\n",
      "\t\t6:15 - 6:19\n",
      "53:0 - 53:5\n",
      "\t0 - 1 (42 frames overlap)\n",
      "\t\t53:0 - 53:3\n",
      "42:40 - 42:45\n",
      "\t1 - 2 (41 frames overlap)\n",
      "\t\t42:43 - 42:45\n",
      "28:30 - 28:35\n",
      "\t0 - 1 (31 frames overlap)\n",
      "\t\t28:30 - 28:32\n",
      "60:30 - 60:35\n",
      "\t0 - 1 (26 frames overlap)\n",
      "\t\t60:30 - 60:31\n",
      "2:10 - 2:15\n",
      "\t0 - 2 (23 frames overlap)\n",
      "\t\t2:10 - 2:14\n"
     ]
    }
   ],
   "source": [
    "# save presented sections to disk\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from tracking import present_section, save_section_presentation\n",
    "\n",
    "# print overlaps ordered by overlap time descendent\n",
    "overlaps = { key: value for key, value in sorted(overlaps.items(), key=lambda item: sum([va[\"overlap\"] for va in item[1].values()]), reverse=True) }\n",
    "\n",
    "# lets also make a video of the overlaps for easier viewing\n",
    "v_out = cv2.VideoWriter(\"overlaps.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), framerate, (1920, 1080))\n",
    "\n",
    "for (section_start, section_end), overlapping_clusters in overlaps.items():\n",
    "    formatted_start = f\"{int(section_start / framerate / 60)}:{int(section_start / framerate % 60)}\"\n",
    "    formatted_end = f\"{int(section_end / framerate / 60)}:{int(section_end / framerate % 60)}\"\n",
    "\n",
    "    print(f\"{formatted_start} - {formatted_end}\")\n",
    "\n",
    "    for (key1, key2), overlap_data in overlapping_clusters.items():\n",
    "        start1, end1 = overlap_data[\"bounds\"][key1]\n",
    "        start2, end2 = overlap_data[\"bounds\"][key2]\n",
    "\n",
    "        start = min(start1, start2)\n",
    "        end = max(end1, end2)\n",
    "\n",
    "        print(f\"\\t{key1} - {key2} ({overlap_data['overlap']} frames overlap)\")\n",
    "        formatted_start = f\"{int(start / framerate / 60)}:{int(start / framerate % 60)}\"\n",
    "        formatted_end = f\"{int(end / framerate / 60)}:{int(end / framerate % 60)}\"\n",
    "        print(f\"\\t\\t{formatted_start} - {formatted_end}\")\n",
    "\n",
    "        artifact_id = get_artifact_id(video_path, start, end, framerate)\n",
    "\n",
    "        _section_detections, sample = make_video_section(start, end)\n",
    "\n",
    "        section_img, section_metadata = present_section(sample, overlap_data[\"clusters\"], version=\"v3\")\n",
    "        \n",
    "        save_section_presentation(artifact_id, section_img, section_metadata)\n",
    "\n",
    "        video_frame = np.array(Image.open(BytesIO(section_img)))\n",
    "        v_out.write(cv2.cvtColor(video_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "v_out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup and setup\n",
    "\n",
    "Now that the sections have been generated, go and manually delete the ones you dont need. (image and metadata)\n",
    "\n",
    "Then, run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "\n",
    "pngs = [f for f in os.listdir(\"./track/presentation\") if f.endswith(\".png\")]\n",
    "artifact_ids = [os.path.basename(f).replace(\".png\", \"\") for f in pngs]\n",
    "\n",
    "if not os.path.exists(\"./.track/ground_truth\"):\n",
    "    os.makedirs(\"./.track/ground_truth\")\n",
    "\n",
    "for png in pngs:\n",
    "    csv = png.replace(\".png\", \".csv\")\n",
    "\n",
    "    if not os.path.isfile(os.path.join(\"./track/ground_truth\", csv)):\n",
    "        open(os.path.join(\"./track/ground_truth\", csv), \"w\").close()\n",
    "\n",
    "def load_ground_truth(artifact_id) -> Optional[dict[str, bool]]:\n",
    "    ## example ground truth file:\n",
    "    ## A, True\n",
    "    ## B, False\n",
    "\n",
    "    output_dir = os.path.join(os.getcwd(), \"track\", \"ground_truth\")\n",
    "\n",
    "    file_path = os.path.join(output_dir, artifact_id + \".csv\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            return None\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            file_contents = f.read()\n",
    "        \n",
    "        res = {}\n",
    "\n",
    "        for line in file_contents.split(\"\\n\"):\n",
    "            if line.strip() != \"\":\n",
    "                key = line.split(\",\")[0].strip().upper()\n",
    "                value = line.split(\",\")[1].strip()\n",
    "\n",
    "                res[key] = value in [\"True\", \"true\", \"1\", \"yes\", \"Yes\", \"YES\"]\n",
    "\n",
    "        return res\n",
    "    else:\n",
    "        print(f\"File {file_path} does not exist\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "def get_score(ground_truth: dict[str, bool], response: dict[str, bool]) -> float:\n",
    "    if len(ground_truth) == 0:\n",
    "        return 0\n",
    "\n",
    "    score = 0\n",
    "    for key in ground_truth:\n",
    "        if key not in response.keys():\n",
    "            print(f\"Key {key} not in response, skipping\")\n",
    "            continue\n",
    "\n",
    "        if ground_truth[key] == response[key]:\n",
    "            score += 1\n",
    "    \n",
    "    print(f\"Expected: [{ground_truth}]\")\n",
    "    print(f\"Received: [{response}]\")\n",
    "    \n",
    "    return score / len(ground_truth)\n",
    "\n",
    "def calc_scores():\n",
    "    ground_truths = [{}] * len(artifact_ids)\n",
    "    scores = [0.0] * len(artifact_ids)\n",
    "\n",
    "    for idx, artifact_id in enumerate(artifact_ids):\n",
    "        ground_truth = load_ground_truth(artifact_id)\n",
    "\n",
    "        if ground_truth is None:\n",
    "            print(f\"Ground truth for {artifact_id} does not exist, skipping\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Loaded ground truth for {artifact_id}\")\n",
    "\n",
    "        ground_truths[idx] = ground_truth\n",
    "\n",
    "        response = responses[idx]\n",
    "\n",
    "        score = get_score(ground_truth, response)\n",
    "\n",
    "        print(f\"Score: {score}\\n\")\n",
    "\n",
    "        scores[idx] = score\n",
    "\n",
    "    print(f\"Overall score: {sum(scores) / len(scores)}\")\n",
    "\n",
    "    # show a dot for every data point int the graph, and also a line connecting them\n",
    "    # also show the id next to the dot, rotated 90 degrees\n",
    "    plt.plot(scores, 'o-')\n",
    "\n",
    "    for idx, score in enumerate(scores):\n",
    "        plt.text(idx, score, artifact_ids[idx], ha='center', va='center', fontsize=8, rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, call gpt4 vision for each presented section in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from tracking import load_section_presentation, load_gpt4_response, save_gpt4_response, parse_claude_response, ask_gippity_for_primary_clusters\n",
    "\n",
    "responses = [{}] * len(artifact_ids)\n",
    "\n",
    "for idx, artifact_id in enumerate(artifact_ids):\n",
    "    section_img, section_metadata = load_section_presentation(artifact_id)\n",
    "\n",
    "    if section_img is None or section_metadata is None:\n",
    "        raise Exception(\"Error loading section presentation\")\n",
    "\n",
    "    loaded_response = load_gpt4_response(artifact_id)\n",
    "\n",
    "    if loaded_response is not None:\n",
    "        print(f\"[VacomCam] Loaded response from cache ({artifact_id})\")\n",
    "        gpt4_response = loaded_response\n",
    "    else:\n",
    "        print(f\"[VacomCam] Submitting section to Claude-3 ({artifact_id})\")\n",
    "        gpt4_response = ask_gippity_for_primary_clusters(section_img, section_metadata, version=\"v3\")\n",
    "    \n",
    "        if gpt4_response is None:\n",
    "            print(\"GPT-4 response was None, SAVING EMPTY RESPONSE\")\n",
    "\n",
    "        save_gpt4_response(artifact_id, gpt4_response)\n",
    "\n",
    "    gpt4_response_parsed = parse_claude_response(gpt4_response)\n",
    "\n",
    "    if gpt4_response_parsed is None:\n",
    "        print(\"GPT-4 response could not be parsed, skipping section\")\n",
    "        continue\n",
    "\n",
    "    responses[idx] = gpt4_response_parsed\n",
    "\n",
    "    # sleep for 15 seconds to avoid rate limiting\n",
    "    time.sleep(15)\n",
    "\n",
    "print(\"[VacomCam] Done processing video sections\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

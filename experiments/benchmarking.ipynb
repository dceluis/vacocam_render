{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193c8cd6-94c2-4592-becd-d13978e5f27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T21:39:56.773512Z",
     "iopub.status.busy": "2023-11-17T21:39:56.772649Z",
     "iopub.status.idle": "2023-11-17T21:40:00.163163Z",
     "shell.execute_reply": "2023-11-17T21:40:00.162462Z",
     "shell.execute_reply.started": "2023-11-17T21:39:56.773484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics[lapx] in /usr/local/lib/python3.9/dist-packages (8.0.211)\n",
      "Requirement already satisfied: sahi==0.11.15 in /usr/local/lib/python3.9/dist-packages (0.11.15)\n",
      "Requirement already satisfied: line_profiler[ipython] in /usr/local/lib/python3.9/dist-packages (4.0.3)\n",
      "Requirement already satisfied: ipython==8.5.0 in /usr/local/lib/python3.9/dist-packages (8.5.0)\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.9/dist-packages (0.2.0)\n",
      "Collecting imutils==0.5.4\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (8.1.3)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (4.64.1)\n",
      "Requirement already satisfied: opencv-python<=4.8 in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (4.6.0.66)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (9.2.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (0.5.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (5.4.1)\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (3.1.10)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (2.0.2)\n",
      "Requirement already satisfied: pybboxes==0.1.6 in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (0.1.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from sahi==0.11.15) (2.28.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (5.1.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (3.0.36)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (5.8.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (2.14.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython==8.5.0) (0.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pybboxes==0.1.6->sahi==0.11.15) (1.23.4)\n",
      "\u001b[33mWARNING: ultralytics 8.0.211 does not provide the extra 'lapx'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (1.12.1+cu116)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (3.6.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (0.13.1+cu116)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (1.5.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (0.12.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (1.9.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics[lapx]) (5.9.4)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from ffmpeg-python) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython==8.5.0) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->ultralytics[lapx]) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics[lapx]) (2022.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython==8.5.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython==8.5.0) (0.2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->sahi==0.11.15) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->sahi==0.11.15) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->sahi==0.11.15) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->sahi==0.11.15) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics[lapx]) (4.4.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->sahi==0.11.15) (2.2.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire->sahi==0.11.15) (1.14.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython==8.5.0) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython==8.5.0) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython==8.5.0) (0.2.2)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25836 sha256=632b13041b31a3e645050e55b4320b7508821ef39a907542a7dcc7c2e1b7503c\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/4b/8b/a9c23da464a09c6ad0a131c1752079bc85f9f1677c7b78e87d\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install ultralytics[lapx] sahi==0.11.15 line_profiler[ipython] ipython==8.5.0 ffmpeg-python imutils==0.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316c286e-4b86-47fb-a207-e36806e354f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T23:45:30.604788Z",
     "iopub.status.busy": "2023-11-16T23:45:30.604205Z",
     "iopub.status.idle": "2023-11-16T23:46:31.285911Z",
     "shell.execute_reply": "2023-11-16T23:46:31.285283Z",
     "shell.execute_reply.started": "2023-11-16T23:45:30.604762Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 60.543 s\n",
       "File: /notebooks/slicing.py\n",
       "Function: run_one at line 399\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   399                                           def run_one(video_path, model_path, max_frames=None, progress=False):\n",
       "   400         1     134306.0 134306.0      0.2      model = YOLO(model=model_path)\n",
       "   401                                           \n",
       "   402         1         13.7     13.7      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   403         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   404                                               \n",
       "   405         1          0.6      0.6      0.0      if not video_name:\n",
       "   406                                                   print(\"error no video name\")\n",
       "   407                                                   return\n",
       "   408         1        434.2    434.2      0.0      elif not os.path.exists(video_path):\n",
       "   409                                                   print(f\"video path {video_path} does not exist\")\n",
       "   410                                                   return\n",
       "   411                                           \n",
       "   412                                               # Open the video file\n",
       "   413         1      34705.0  34705.0      0.1      cap = cv2.VideoCapture(video_path)\n",
       "   414                                           \n",
       "   415                                               # get the number of frames\n",
       "   416         1         18.7     18.7      0.0      video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   417                                               \n",
       "   418         1          1.7      1.7      0.0      original_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   419         1          1.4      1.4      0.0      original_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   420         1          0.8      0.8      0.0      current_frame_num = 0\n",
       "   421         1          0.8      0.8      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   422         1          0.8      0.8      0.0      if progress:\n",
       "   423         1       2166.0   2166.0      0.0          pbar = tqdm(total=total_frame_num)\n",
       "   424                                           \n",
       "   425                                               # Loop through the video frames\n",
       "   426       900       6490.7      7.2      0.0      while cap.isOpened() and (current_frame_num < total_frame_num):\n",
       "   427                                                   # Read a frame from the video\n",
       "   428       900    2861636.6   3179.6      4.7          success, frame = cap.read()\n",
       "   429       900       1671.2      1.9      0.0          current_frame_num = current_frame_num + 1\n",
       "   430                                           \n",
       "   431       900        779.6      0.9      0.0          if success:                        \n",
       "   432       900     163431.0    181.6      0.3              slice_image_result = slice_image(\n",
       "   433       900        847.8      0.9      0.0                  image=frame,\n",
       "   434       900        812.0      0.9      0.0                  slice_height=640,\n",
       "   435       900        935.7      1.0      0.0                  slice_width=640,\n",
       "   436       900        805.2      0.9      0.0                  overlap_height_ratio=0.2,\n",
       "   437       900        517.3      0.6      0.0                  overlap_width_ratio=0.2,\n",
       "   438       900        472.6      0.5      0.0                  auto_slice_resolution=True,\n",
       "   439                                                       )\n",
       "   440                                                       \n",
       "   441       900   56901652.3  63224.1     94.0              model.predict(source=slice_image_result.images, device=\"cuda:0\", conf=0.5, verbose=False)\n",
       "   442                                           \n",
       "   443       900        948.8      1.1      0.0              if progress:\n",
       "   444       900     428149.5    475.7      0.7                  pbar.update(1)\n",
       "   445                                                   else:\n",
       "   446                                                       # Break the loop if the end of the video is reached\n",
       "   447                                                       break\n",
       "   448                                           \n",
       "   449         1       2230.1   2230.1      0.0      cap.release()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_one\n",
    "\n",
    "%lprun -f run_one -u 1e-06 run_one(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167ecd90-2b05-4d0f-81c0-c13079d18b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:22:20.946552Z",
     "iopub.status.busy": "2023-11-17T04:22:20.946024Z",
     "iopub.status.idle": "2023-11-17T04:22:25.741703Z",
     "shell.execute_reply": "2023-11-17T04:22:25.741101Z",
     "shell.execute_reply.started": "2023-11-17T04:22:20.946530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/906 [00:00<?, ?it/s]ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'samples/sample.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:30.02, start: 0.000000, bitrate: 10104 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1440, 9907 kb/s, 30 fps, 30 tbr, 90k tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandle\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandle\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> rawvideo (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, rawvideo, to 'pipe:':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(eng): Video: rawvideo (BGR[24] / 0x18524742), bgr24, 1920x1440, q=2-31, 1990656 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandle\n",
      "      encoder         : Lavc58.54.100 rawvideo\n",
      "  8%|▊         | 74/906 [00:04<00:51, 16.16it/s]rame=    9 fps=0.0 q=-0.0 size=   72900kB time=00:00:00.30 bitrate=1990656.0kbits/s speed=0.596x    frame=   18 fps= 17 q=-0.0 size=  145800kB time=00:00:00.60 bitrate=1990656.0kbits/s speed=0.559x    frame=   28 fps= 17 q=-0.0 size=  226800kB time=00:00:00.93 bitrate=1990656.7kbits/s speed=0.568x    frame=   38 fps= 17 q=-0.0 size=  307800kB time=00:00:01.26 bitrate=1990655.5kbits/s speed=0.568x    frame=   48 fps= 17 q=-0.0 size=  388800kB time=00:00:01.60 bitrate=1990656.0kbits/s speed=0.572x    frame=   58 fps= 17 q=-0.0 size=  469800kB time=00:00:01.93 bitrate=1990656.3kbits/s speed=0.576x    frame=   68 fps= 17 q=-0.0 size=  550800kB time=00:00:02.26 bitrate=1990655.7kbits/s speed=0.577x    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 4.6328 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_two at line 457\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   457                                                           auto_slice_resolution=False,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_two\n",
    "\n",
    "%lprun -f run_two -u 1e-06 run_two(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc83cc4-dc91-48c0-b549-fb6590e9983d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:23:44.625405Z",
     "iopub.status.busy": "2023-11-17T04:23:44.625029Z",
     "iopub.status.idle": "2023-11-17T04:24:26.781360Z",
     "shell.execute_reply": "2023-11-17T04:24:26.780834Z",
     "shell.execute_reply.started": "2023-11-17T04:23:44.625381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [00:41<00:00, 21.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 42.008 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_two_imtools at line 488\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   488                                           def run_two_imtools(video_path, model_path, max_frames=None, progress=False):\n",
       "   489         1      35634.9  35634.9      0.1      model = YOLO(model=model_path)\n",
       "   490                                           \n",
       "   491         1         13.1     13.1      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   492         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   493                                               \n",
       "   494         1          0.6      0.6      0.0      if not video_name:\n",
       "   495                                                   print(\"error no video name\")\n",
       "   496                                                   return\n",
       "   497         1       2627.6   2627.6      0.0      elif not os.path.exists(video_path):\n",
       "   498                                                   print(f\"video path {video_path} does not exist\")\n",
       "   499                                                   return\n",
       "   500                                           \n",
       "   501                                               # Open the video file\n",
       "   502         1      33630.0  33630.0      0.1      cap = FileVideoStream(path=video_path, queue_size=128, transform=None).start()\n",
       "   503                                           \n",
       "   504                                               # get the number of frames\n",
       "   505         1         13.5     13.5      0.0      video_frame_count = int(cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   506                                               \n",
       "   507         1          2.0      2.0      0.0      original_width = cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   508         1          1.6      1.6      0.0      original_height = cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   509                                           \n",
       "   510         1          1.1      1.1      0.0      current_frame_num = 0\n",
       "   511         1          1.0      1.0      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   512                                               \n",
       "   513         1          0.6      0.6      0.0      if progress:\n",
       "   514         1       2757.4   2757.4      0.0          pbar = tqdm(total=total_frame_num)\n",
       "   515                                               \n",
       "   516         1          0.8      0.8      0.0      images = []\n",
       "   517                                           \n",
       "   518                                               # Loop through the video frames\n",
       "   519       901     104629.5    116.1      0.2      while cap.more() and (current_frame_num < total_frame_num):\n",
       "   520                                                   # Read a frame from the video\n",
       "   521       901       7318.4      8.1      0.0          frame = cap.read()\n",
       "   522       901        749.2      0.8      0.0          current_frame_num += 1\n",
       "   523                                           \n",
       "   524       900        555.3      0.6      0.0          if frame is not None:\n",
       "   525       900      65401.4     72.7      0.2              slice_image_result = slice_image(\n",
       "   526       900        497.8      0.6      0.0                  image=frame,\n",
       "   527       900        536.9      0.6      0.0                  slice_height=640,\n",
       "   528       900        496.4      0.6      0.0                  slice_width=640,\n",
       "   529       900        508.3      0.6      0.0                  overlap_height_ratio=0.2,\n",
       "   530       900        506.9      0.6      0.0                  overlap_width_ratio=0.2,\n",
       "   531       900        503.4      0.6      0.0                  auto_slice_resolution=False,\n",
       "   532                                                       )\n",
       "   533                                                       \n",
       "   534       900       3418.1      3.8      0.0              images.append(slice_image_result.images)\n",
       "   535                                           \n",
       "   536       900        543.0      0.6      0.0              if progress:\n",
       "   537       900     228861.9    254.3      0.5                  pbar.update(1)\n",
       "   538                                           \n",
       "   539       676       2711.0      4.0      0.0          if len(images) > 3 or (not cap.more() and (len(images) > 0)):\n",
       "   540       225       1441.1      6.4      0.0              source = list(itertools.chain(*images))\n",
       "   541       225   41513770.7 184505.6     98.8              model.predict(source=source, device=\"cuda:0\", conf=0.5, verbose=False)\n",
       "   542       225        824.4      3.7      0.0              images = []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_two_imtools\n",
    "\n",
    "%lprun -f run_two_imtools -u 1e-06 run_two_imtools(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc7cb20-be19-443c-908f-ed9588a2faf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:24:39.893570Z",
     "iopub.status.busy": "2023-11-17T04:24:39.893299Z",
     "iopub.status.idle": "2023-11-17T04:25:16.515050Z",
     "shell.execute_reply": "2023-11-17T04:25:16.514395Z",
     "shell.execute_reply.started": "2023-11-17T04:24:39.893551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/906 [00:00<03:29,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [00:36<00:00, 24.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 36.5036 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_three at line 544\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   544                                           def run_three(video_path, model_path, max_frames=None, progress=False):\n",
       "   545         1      31185.7  31185.7      0.1      model = YOLO(model=model_path)\n",
       "   546                                           \n",
       "   547         1         13.6     13.6      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   548         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   549                                               \n",
       "   550         1          0.6      0.6      0.0      if not video_name:\n",
       "   551                                                   print(\"error no video name\")\n",
       "   552                                                   return\n",
       "   553         1       1351.9   1351.9      0.0      elif not os.path.exists(video_path):\n",
       "   554                                                   print(f\"video path {video_path} does not exist\")\n",
       "   555                                                   return\n",
       "   556                                           \n",
       "   557                                               # Open the video file\n",
       "   558         1      32290.5  32290.5      0.1      cap = FileVideoStream(path=video_path, queue_size=128, transform=None).start()\n",
       "   559                                           \n",
       "   560                                               # get the number of frames\n",
       "   561         1          9.1      9.1      0.0      video_frame_count = int(cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   562                                               \n",
       "   563         1          1.6      1.6      0.0      original_width = cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   564         1          1.4      1.4      0.0      original_height = cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   565                                           \n",
       "   566         1          0.9      0.9      0.0      current_frame_num = 0\n",
       "   567         1         10.4     10.4      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   568         1          0.6      0.6      0.0      if progress:\n",
       "   569         1       1515.8   1515.8      0.0          pbar = tqdm(total=total_frame_num)\n",
       "   570                                           \n",
       "   571                                               # Loop through the video frames\n",
       "   572       901     109605.4    121.6      0.3      while cap.more() and (current_frame_num < total_frame_num):\n",
       "   573       901      12403.0     13.8      0.0          frame = cap.read()\n",
       "   574                                                   \n",
       "   575       900        620.6      0.7      0.0          if frame is not None:\n",
       "   576       900        808.2      0.9      0.0              current_frame_num = current_frame_num + 1\n",
       "   577                                           \n",
       "   578       900      89710.6     99.7      0.2              slice_image_result = slice_image(\n",
       "   579       900        464.0      0.5      0.0                  image=frame,\n",
       "   580       900        614.4      0.7      0.0                  slice_height=640,\n",
       "   581       900        470.1      0.5      0.0                  slice_width=640,\n",
       "   582       900        582.9      0.6      0.0                  overlap_height_ratio=0.2,\n",
       "   583       900        475.5      0.5      0.0                  overlap_width_ratio=0.2,\n",
       "   584       900        476.1      0.5      0.0                  auto_slice_resolution=True,\n",
       "   585                                                       )\n",
       "   586                                           \n",
       "   587       899        686.4      0.8      0.0              if current_frame_num == 1: \n",
       "   588         1         95.3     95.3      0.0                  print(f\"type: {type(slice_image_result.images)}\")\n",
       "   589                                           \n",
       "   590       900   35884243.6  39871.4     98.3              model.predict(source=slice_image_result.images, device=\"cuda:0\", conf=0.5, verbose=False)\n",
       "   591                                           \n",
       "   592       900        911.7      1.0      0.0              if progress:\n",
       "   593       900     334989.5    372.2      0.9                  pbar.update(1)\n",
       "   594                                           \n",
       "   595         1          4.1      4.1      0.0      if cap.running():\n",
       "   596                                                   cap.stop()\n",
       "   597                                                   \n",
       "   598         1          0.9      0.9      0.0      del frame\n",
       "   599         1          3.8      3.8      0.0      del cap.Q\n",
       "   600         1         12.6     12.6      0.0      del cap"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_three\n",
    "\n",
    "%lprun -f run_three -u 1e-06 run_three(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d78713-01fd-4e52-bf0d-6f4403ab2f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T07:10:59.726291Z",
     "iopub.status.busy": "2023-11-17T07:10:59.725415Z",
     "iopub.status.idle": "2023-11-17T07:11:04.403073Z",
     "shell.execute_reply": "2023-11-17T07:11:04.402470Z",
     "shell.execute_reply.started": "2023-11-17T07:10:59.726244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/906 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2.86018 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_four at line 754\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   754                                           def run_four(video_path, model_path, max_frames=None, progress=False):\n",
       "   755         1    1601170.9 1601170.9     56.0      sahi_model = Yolov8DetectionModel(\n",
       "   756         1          0.6      0.6      0.0          model_path=model_path,\n",
       "   757         1          0.6      0.6      0.0          confidence_threshold=0.5,\n",
       "   758         1          0.8      0.8      0.0          image_size=640,\n",
       "   759         1          0.5      0.5      0.0          device=\"cuda:0\",  # or 'cuda:0'\n",
       "   760                                               )\n",
       "   761                                           \n",
       "   762         1         15.6     15.6      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   763         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   764                                               \n",
       "   765         1          0.5      0.5      0.0      if not video_name:\n",
       "   766                                                   print(\"error no video name\")\n",
       "   767                                                   return\n",
       "   768         1        433.4    433.4      0.0      elif not os.path.exists(video_path):\n",
       "   769                                                   print(f\"video path {video_path} does not exist\")\n",
       "   770                                                   return\n",
       "   771                                           \n",
       "   772                                               # Open the video file\n",
       "   773         1      32432.4  32432.4      1.1      cap = cv2.VideoCapture(video_path)\n",
       "   774                                           \n",
       "   775                                               # get the number of frames\n",
       "   776         1         22.5     22.5      0.0      video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   777                                               \n",
       "   778         1          2.0      2.0      0.0      original_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   779         1          2.7      2.7      0.0      original_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   780                                           \n",
       "   781         1          0.6      0.6      0.0      current_frame_num = 0\n",
       "   782         1          1.5      1.5      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   783         1          1.1      1.1      0.0      if progress:\n",
       "   784         1       6833.8   6833.8      0.2          pbar = tqdm(total=total_frame_num)\n",
       "   785                                           \n",
       "   786                                               # Loop through the video frames\n",
       "   787         1         11.4     11.4      0.0      while cap.isOpened() and (current_frame_num < total_frame_num):\n",
       "   788                                                   # Read a frame from the video\n",
       "   789         1      55526.4  55526.4      1.9          success, frame = cap.read()\n",
       "   790         1          3.2      3.2      0.0          current_frame_num = current_frame_num + 1\n",
       "   791                                           \n",
       "   792         1          1.5      1.5      0.0          if success:\n",
       "   793                                                       # Getting prediction using model\n",
       "   794         1    1163710.8 1163710.8     40.7              results = get_sliced_prediction(\n",
       "   795         1          0.6      0.6      0.0                  frame,\n",
       "   796         1          1.1      1.1      0.0                  sahi_model,\n",
       "   797         1          1.3      1.3      0.0                  slice_height=640,\n",
       "   798         1          0.7      0.7      0.0                  slice_width=640,\n",
       "   799         1          0.6      0.6      0.0                  overlap_height_ratio=0.2,\n",
       "   800         1          0.5      0.5      0.0                  overlap_width_ratio=0.2,\n",
       "   801         1          0.7      0.7      0.0                  perform_standard_pred=False,\n",
       "   802         1          0.5      0.5      0.0                  verbose=0,\n",
       "   803                                                       )\n",
       "   804                                           \n",
       "   805                                                       if progress:\n",
       "   806                                                           pbar.update(1)\n",
       "   807                                                   else:\n",
       "   808                                                       # Break the loop if the end of the video is reached\n",
       "   809                                                       break\n",
       "   810                                           \n",
       "   811                                               # Release the video capture object and close the display window\n",
       "   812                                               cap.release()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_four\n",
    "\n",
    "%lprun -f run_four -u 1e-06 run_four(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d870dc6-8adc-4509-b4ff-e59987ef12b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T07:07:46.295284Z",
     "iopub.status.busy": "2023-11-17T07:07:46.294732Z",
     "iopub.status.idle": "2023-11-17T07:08:37.012731Z",
     "shell.execute_reply": "2023-11-17T07:08:37.011999Z",
     "shell.execute_reply.started": "2023-11-17T07:07:46.295250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [00:47<00:00, 19.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 48.9158 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_four_batched at line 814\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   814                                           def run_four_batched(video_path, model_path, max_frames=None, progress=False):\n",
       "   815         1    1641174.6 1641174.6      3.4      sahi_model = Yolov8BatchedDetectionModel(\n",
       "   816         1          0.7      0.7      0.0          model_path=model_path,\n",
       "   817         1          0.7      0.7      0.0          confidence_threshold=0.5,\n",
       "   818         1          0.6      0.6      0.0          image_size=640,\n",
       "   819         1          0.6      0.6      0.0          device=\"cuda:0\",  # or 'cuda:0'\n",
       "   820                                               )\n",
       "   821                                           \n",
       "   822         1         17.0     17.0      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   823         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   824                                               \n",
       "   825         1          0.6      0.6      0.0      if not video_name:\n",
       "   826                                                   print(\"error no video name\")\n",
       "   827                                                   return\n",
       "   828         1         31.1     31.1      0.0      elif not os.path.exists(video_path):\n",
       "   829                                                   print(f\"video path {video_path} does not exist\")\n",
       "   830                                                   return\n",
       "   831                                           \n",
       "   832                                               # Open the video file\n",
       "   833         1      31969.0  31969.0      0.1      cap = cv2.VideoCapture(video_path)\n",
       "   834                                           \n",
       "   835                                               # get the number of frames\n",
       "   836         1          0.0      0.0      0.0      video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   837                                               \n",
       "   838         1          2.5      2.5      0.0      original_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   839         1          3.0      3.0      0.0      original_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   840                                           \n",
       "   841         1          1.0      1.0      0.0      current_frame_num = 0\n",
       "   842         1          1.1      1.1      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   843         1          1.0      1.0      0.0      if progress:\n",
       "   844         1       5606.8   5606.8      0.0          pbar = tqdm(total=total_frame_num)\n",
       "   845                                           \n",
       "   846                                               # Loop through the video frames\n",
       "   847       901       6130.7      6.8      0.0      while cap.isOpened() and (current_frame_num < total_frame_num):\n",
       "   848                                                   # Read a frame from the video\n",
       "   849       901    3429331.9   3806.1      7.0          success, frame = cap.read()\n",
       "   850       901       1743.2      1.9      0.0          current_frame_num = current_frame_num + 1\n",
       "   851                                           \n",
       "   852       900        973.7      1.1      0.0          if success:\n",
       "   853                                                       # Getting prediction using model\n",
       "   854       900   43447610.1  48275.1     88.8              results = get_sliced_prediction_new(\n",
       "   855       900        570.9      0.6      0.0                  frame,\n",
       "   856       900        619.4      0.7      0.0                  sahi_model,\n",
       "   857       900       1007.0      1.1      0.0                  slice_height=640,\n",
       "   858       900        532.6      0.6      0.0                  slice_width=640,\n",
       "   859       900        641.3      0.7      0.0                  overlap_height_ratio=0.2,\n",
       "   860       900        623.2      0.7      0.0                  overlap_width_ratio=0.2,\n",
       "   861       900        497.5      0.6      0.0                  verbose=0,\n",
       "   862                                                       )\n",
       "   863                                           \n",
       "   864       900        756.6      0.8      0.0              if progress:\n",
       "   865       900     344575.9    382.9      0.7                  pbar.update(1)\n",
       "   866                                                   else:\n",
       "   867                                                       # Break the loop if the end of the video is reached\n",
       "   868                                                       break\n",
       "   869                                           \n",
       "   870                                               # Release the video capture object and close the display window\n",
       "   871         1       1374.5   1374.5      0.0      cap.release()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_four_batched\n",
    "\n",
    "%lprun -f run_four_batched -u 1e-06 run_four_batched(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6505f48-f761-43d4-b0f3-84da323a2505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T03:47:21.177292Z",
     "iopub.status.busy": "2023-11-17T03:47:21.176524Z",
     "iopub.status.idle": "2023-11-17T03:50:36.434170Z",
     "shell.execute_reply": "2023-11-17T03:50:36.433513Z",
     "shell.execute_reply.started": "2023-11-17T03:47:21.177270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [03:14<00:01,  4.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 195.137 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_five at line 707\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   707                                           \n",
       "   708         1     256037.4 256037.4      0.1  def run_five(video_path, model_path, max_frames=None, progress=False):\n",
       "   709         1          0.5      0.5      0.0      sahi_model = AutoDetectionModel.from_pretrained(\n",
       "   710         1          0.5      0.5      0.0          model_type='yolov8',\n",
       "   711         1          0.5      0.5      0.0          model_path=model_path,\n",
       "   712         1          0.5      0.5      0.0          confidence_threshold=0.5,\n",
       "   713         1          0.5      0.5      0.0          image_size=640,\n",
       "   714                                                   device=\"cuda:0\",  # or 'cuda:0'\n",
       "   715                                               )\n",
       "   716         1         17.5     17.5      0.0  \n",
       "   717         1          0.6      0.6      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   718                                               video_dir = video_dir or os.getcwd()\n",
       "   719         1          0.5      0.5      0.0      \n",
       "   720                                               if not video_name:\n",
       "   721                                                   print(\"error no video name\")\n",
       "   722         1        497.6    497.6      0.0          return\n",
       "   723                                               elif not os.path.exists(video_path):\n",
       "   724                                                   print(f\"video path {video_path} does not exist\")\n",
       "   725                                                   return\n",
       "   726                                           \n",
       "   727         1      29601.1  29601.1      0.0      # Open the video file\n",
       "   728                                               cap = FileVideoStream(path=video_path, queue_size=128, transform=None).start()\n",
       "   729                                           \n",
       "   730         1          3.4      3.4      0.0      # get the number of frames\n",
       "   731                                               video_frame_count = int(cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   732         1          1.5      1.5      0.0      \n",
       "   733         1          1.7      1.7      0.0      original_width = cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   734                                               original_height = cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   735         1          1.1      1.1      0.0  \n",
       "   736         1          0.7      0.7      0.0      current_frame_num = 0\n",
       "   737         1          0.5      0.5      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   738         1       1427.9   1427.9      0.0      if progress:\n",
       "   739                                                   pbar = tqdm(total=total_frame_num)\n",
       "   740                                           \n",
       "   741       901     110098.4    122.2      0.1      # Loop through the video frames\n",
       "   742                                               while cap.more() and (current_frame_num < total_frame_num):\n",
       "   743       901      37049.3     41.1      0.0          # Read a frame from the video\n",
       "   744       901       1190.3      1.3      0.0          frame = cap.read()\n",
       "   745                                                   current_frame_num = current_frame_num + 1\n",
       "   746       900        595.9      0.7      0.0  \n",
       "   747                                                   if frame is not None:\n",
       "   748       900  193829433.9 215366.0     99.3              # Getting prediction using model\n",
       "   749       900        443.2      0.5      0.0              results = get_sliced_prediction(\n",
       "   750       900        542.3      0.6      0.0                  frame,\n",
       "   751       900        517.7      0.6      0.0                  sahi_model,\n",
       "   752       900        424.1      0.5      0.0                  slice_height=640,\n",
       "   753       900        432.4      0.5      0.0                  slice_width=640,\n",
       "   754       900        435.7      0.5      0.0                  overlap_height_ratio=0.2,\n",
       "   755       900        444.8      0.5      0.0                  overlap_width_ratio=0.2,\n",
       "   756       900        405.0      0.5      0.0                  perform_standard_pred=False,\n",
       "   757                                                           verbose=0,\n",
       "   758                                                       )\n",
       "   759       900       1128.4      1.3      0.0  \n",
       "   760       900     866566.9    962.9      0.4              if progress:\n",
       "   761                                                           pbar.update(1)\n",
       "   762         1          3.8      3.8      0.0  \n",
       "   763                                               if cap.running():\n",
       "   764                                                   cap.stop()\n",
       "   765         1          0.8      0.8      0.0          \n",
       "   766         1          6.7      6.7      0.0      del frame\n",
       "   767         1         15.8     15.8      0.0      del cap.Q\n",
       "   768                                               del cap"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_five\n",
    "\n",
    "%lprun -f run_five -u 1e-06 run_five(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fb5060-0992-4559-bdec-313400e7c25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T21:41:44.696184Z",
     "iopub.status.busy": "2023-11-17T21:41:44.695866Z",
     "iopub.status.idle": "2023-11-17T21:42:27.352793Z",
     "shell.execute_reply": "2023-11-17T21:42:27.352069Z",
     "shell.execute_reply.started": "2023-11-17T21:41:44.696184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [00:39<00:00, 22.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 41.0493 s\n",
       "File: /notebooks/benchmarking.py\n",
       "Function: run_five_batched at line 451\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   451                                           def run_five_batched(video_path, model_path, max_frames=None, progress=False):\n",
       "   452         1    1796825.0 1796825.0      4.4      sahi_model = Yolov8BatchedDetectionModel(\n",
       "   453         1          0.6      0.6      0.0          model_path=model_path,\n",
       "   454         1          0.6      0.6      0.0          confidence_threshold=0.5,\n",
       "   455         1          1.3      1.3      0.0          image_size=640,\n",
       "   456         1          0.6      0.6      0.0          device=\"cuda:0\",  # or 'cuda:0'\n",
       "   457                                               )\n",
       "   458                                           \n",
       "   459         1         17.3     17.3      0.0      video_dir, video_name = os.path.split(video_path)\n",
       "   460         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
       "   461                                               \n",
       "   462         1          0.5      0.5      0.0      if not video_name:\n",
       "   463                                                   print(\"error no video name\")\n",
       "   464                                                   return\n",
       "   465         1         25.4     25.4      0.0      elif not os.path.exists(video_path):\n",
       "   466                                                   print(f\"video path {video_path} does not exist\")\n",
       "   467                                                   return\n",
       "   468                                           \n",
       "   469                                               # Open the video file\n",
       "   470         1      33610.4  33610.4      0.1      cap = FileVideoStream(path=video_path, queue_size=128, transform=None).start()\n",
       "   471                                           \n",
       "   472                                               # get the number of frames\n",
       "   473         1         24.2     24.2      0.0      video_frame_count = int(cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
       "   474                                               \n",
       "   475         1          2.0      2.0      0.0      original_width = cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
       "   476         1          1.7      1.7      0.0      original_height = cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
       "   477                                           \n",
       "   478         1          0.8      0.8      0.0      current_frame_num = 0\n",
       "   479         1          0.6      0.6      0.0      total_frame_num = (max_frames or video_frame_count)\n",
       "   480         1          0.6      0.6      0.0      if progress:\n",
       "   481         1       4947.5   4947.5      0.0          pbar = tqdm(total=total_frame_num)\n",
       "   482                                           \n",
       "   483                                               # Loop through the video frames\n",
       "   484       901     109837.9    121.9      0.3      while cap.more() and (current_frame_num < total_frame_num):\n",
       "   485                                                   # Read a frame from the video\n",
       "   486       901      12534.0     13.9      0.0          frame = cap.read()\n",
       "   487       901        721.2      0.8      0.0          current_frame_num = current_frame_num + 1\n",
       "   488                                           \n",
       "   489       900        572.6      0.6      0.0          if frame is not None:\n",
       "   490                                                       # Getting prediction using model\n",
       "   491       900   38777223.3  43085.8     94.5              results = get_sliced_prediction_new(\n",
       "   492       900        456.3      0.5      0.0                  frame,\n",
       "   493       900        470.6      0.5      0.0                  sahi_model,\n",
       "   494       900        619.0      0.7      0.0                  slice_height=640,\n",
       "   495       900        454.7      0.5      0.0                  slice_width=640,\n",
       "   496       900        491.8      0.5      0.0                  overlap_height_ratio=0.2,\n",
       "   497       900        456.2      0.5      0.0                  overlap_width_ratio=0.2,\n",
       "   498       900        452.3      0.5      0.0                  verbose=0,\n",
       "   499                                                       )\n",
       "   500                                           \n",
       "   501       900        740.6      0.8      0.0              if progress:\n",
       "   502       900     308790.3    343.1      0.8                  pbar.update(1)\n",
       "   503                                           \n",
       "   504         1          4.8      4.8      0.0      if cap.running():\n",
       "   505                                                   cap.stop()\n",
       "   506                                                   \n",
       "   507         1          0.5      0.5      0.0      del frame\n",
       "   508         1          4.5      4.5      0.0      del cap.Q\n",
       "   509         1         15.1     15.1      0.0      del cap"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "from benchmarking import run_five_batched\n",
    "\n",
    "%lprun -f run_five_batched -u 1e-06 run_five_batched(\"samples/sample.mp4\", model_path, max_frames=None, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfed628-fc6a-4dc1-8ac4-0cd051f0aa17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T22:13:37.374327Z",
     "iopub.status.busy": "2023-11-15T22:13:37.374072Z",
     "iopub.status.idle": "2023-11-15T22:16:25.490718Z",
     "shell.execute_reply": "2023-11-15T22:16:25.489891Z",
     "shell.execute_reply.started": "2023-11-15T22:13:37.374310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\",\"samples/sample-Copy3.mp4\",\"samples/sample-Copy4.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=\"run_one\"\n",
    ")\n",
    "\n",
    "!python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_run_one.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bf6aab-3f7c-458f-bc57-3f43e77b8f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T23:41:42.122042Z",
     "iopub.status.busy": "2023-11-16T23:41:42.121785Z",
     "iopub.status.idle": "2023-11-16T23:43:31.000161Z",
     "shell.execute_reply": "2023-11-16T23:43:30.999271Z",
     "shell.execute_reply.started": "2023-11-16T23:41:42.122022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:44<00:00,  8.63it/s]\n",
      "100%|██████████| 900/900 [01:44<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None]\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 104.721 s\n",
      "File: /notebooks/slicing.py\n",
      "Function: run_two at line 456\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   456                                           def run_two(video_path, model_path, max_frames=None, progress=False):\n",
      "   457         1     493272.9 493272.9      0.5      model = YOLO(model=model_path)\n",
      "   458                                           \n",
      "   459         1         16.0     16.0      0.0      video_dir, video_name = os.path.split(video_path)\n",
      "   460         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
      "   461                                               \n",
      "   462         1          0.5      0.5      0.0      if not video_name:\n",
      "   463                                                   print(\"error no video name\")\n",
      "   464                                                   return\n",
      "   465         1         20.1     20.1      0.0      elif not os.path.exists(video_path):\n",
      "   466                                                   print(f\"video path {video_path} does not exist\")\n",
      "   467                                                   return\n",
      "   468                                           \n",
      "   469                                               # Open the video file\n",
      "   470         1      32382.4  32382.4      0.0      cap = cv2.VideoCapture(video_path)\n",
      "   471                                           \n",
      "   472                                               # get the number of frames\n",
      "   473         1         23.4     23.4      0.0      video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
      "   474         1          1.9      1.9      0.0      original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
      "   475         1          1.7      1.7      0.0      original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
      "   476                                               \n",
      "   477         1        531.2    531.2      0.0      cap.release()\n",
      "   478                                           \n",
      "   479         1          0.7      0.7      0.0      current_frame_num = 0\n",
      "   480         1          1.1      1.1      0.0      total_frame_num = (max_frames or video_frame_count)\n",
      "   481                                               \n",
      "   482         1          0.7      0.7      0.0      if progress:\n",
      "   483         1        863.9    863.9      0.0          pbar = tqdm(total=total_frame_num)\n",
      "   484                                                   \n",
      "   485         1      12470.8  12470.8      0.0      process = start_ffmpeg_process_read(video_path)\n",
      "   486                                               \n",
      "   487         1          1.5      1.5      0.0      images = []\n",
      "   488                                           \n",
      "   489                                               # Loop through the video frames\n",
      "   490       900        649.7      0.7      0.0      while current_frame_num < total_frame_num:\n",
      "   491       900        678.1      0.8      0.0          end_of_stream = False\n",
      "   492                                                   # Read a frame from the video\n",
      "   493       900   12284490.2  13649.4     11.7          frame = read_frame(process, original_width, original_height)\n",
      "   494                                           \n",
      "   495       900       1772.7      2.0      0.0          if frame is not None:\n",
      "   496       900       1049.1      1.2      0.0              current_frame_num += 1\n",
      "   497                                           \n",
      "   498       900     700804.3    778.7      0.7              slice_image_result = slice_image(\n",
      "   499       900        893.2      1.0      0.0                  image=frame,\n",
      "   500       900        625.3      0.7      0.0                  slice_height=640,\n",
      "   501       900       1021.4      1.1      0.0                  slice_width=640,\n",
      "   502       900        539.8      0.6      0.0                  overlap_height_ratio=0.2,\n",
      "   503       900        448.8      0.5      0.0                  overlap_width_ratio=0.2,\n",
      "   504       900        458.8      0.5      0.0                  auto_slice_resolution=True,\n",
      "   505                                                       )\n",
      "   506                                                       \n",
      "   507       900       4664.6      5.2      0.0              images.append(slice_image_result.images)\n",
      "   508                                           \n",
      "   509       900        580.4      0.6      0.0              if progress:\n",
      "   510       900     106814.6    118.7      0.1                  pbar.update(1)\n",
      "   511                                                   else:\n",
      "   512                                                       end_of_stream = True\n",
      "   513                                           \n",
      "   514       900       4565.5      5.1      0.0          print(len(images))\n",
      "   515       450        363.6      0.8      0.0          if len(images) > 1 or (end_of_stream and len(images) > 0):\n",
      "   516       450       3173.4      7.1      0.0              source = list(itertools.chain(*images))\n",
      "   517       450   91066416.5 202369.8     87.0              model.predict(source=source, device=\"cuda:0\", conf=0.5, verbose=False)\n",
      "   518       450       1026.9      2.3      0.0              images = []\n",
      "   519                                                       \n",
      "   520       900        593.3      0.7      0.0          if end_of_stream:\n",
      "   521                                                       logger.info('End of input stream')\n",
      "   522                                                       break\n",
      "   523                                           \n",
      "   524                                               while True:\n",
      "   525         1         22.3     22.3      0.0          ready, _, _ = select.select([process.stdout], [], [], 0.1)\n",
      "   526         1          0.8      0.8      0.0          if ready:\n",
      "   527         1          9.4      9.4      0.0              data = process.stdout.read(65536)\n",
      "   528         1          0.6      0.6      0.0              if not data:\n",
      "   529         1          0.6      0.6      0.0                  break\n",
      "   530                                                   elif process.poll() is not None:\n",
      "   531                                                       break\n",
      "   532                                           \n",
      "   533         1         72.6     72.6      0.0      process.terminate()  # Terminate the process\n",
      "   534         1          4.9      4.9      0.0      process.wait()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=\"run_two\"\n",
    ")\n",
    "\n",
    "!python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_run_two.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dff8fa8-a014-4038-a8fc-2742228dcc36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:28:44.325986Z",
     "iopub.status.busy": "2023-11-17T04:28:44.325714Z",
     "iopub.status.idle": "2023-11-17T04:31:01.768375Z",
     "shell.execute_reply": "2023-11-17T04:31:01.767648Z",
     "shell.execute_reply.started": "2023-11-17T04:28:44.325965Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [02:12<00:00,  6.80it/s]\n",
      " 99%|█████████▉| 900/906 [02:12<00:00,  6.80it/s]\n",
      " 99%|█████████▉| 900/906 [02:12<00:00,  6.80it/s]\n",
      " 99%|█████████▉| 900/906 [02:12<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/__main__.py\", line 4, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/line_profiler.py\", line 324, in main\n",
      "    lstats = load_stats(args.profile_output)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/line_profiler.py\", line 295, in load_stats\n",
      "    with open(filename, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/notebooks/profile_run_sample-Copy1.mp4_.lprof'\n"
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_function_name=\"run_two_imtools\"\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\", \"samples/sample-Copy3.mp4\", \"samples/sample-Copy4.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=run_function_name\n",
    ")\n",
    "\n",
    "command = f\"python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_{run_function_name}.lprof\"\n",
    "\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd10ead-131b-4fd4-a05c-b6ad77144490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:09.550906Z",
     "iopub.status.busy": "2023-11-17T04:33:09.550599Z",
     "iopub.status.idle": "2023-11-17T04:35:20.087821Z",
     "shell.execute_reply": "2023-11-17T04:35:20.087148Z",
     "shell.execute_reply.started": "2023-11-17T04:33:09.550882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [02:05<00:00,  7.17it/s]\n",
      " 99%|█████████▉| 900/906 [02:06<00:00,  7.13it/s]\n",
      " 99%|█████████▉| 900/906 [02:06<00:00,  7.14it/s]\n",
      " 99%|█████████▉| 900/906 [02:05<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'list'>\n",
      "type: <class 'list'>\n",
      "type: <class 'list'>\n",
      "type: <class 'list'>\n",
      "[None, None, None, None]\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 126.764 s\n",
      "File: /notebooks/benchmarking.py\n",
      "Function: run_three at line 544\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   544                                           def run_three(video_path, model_path, max_frames=None, progress=False):\n",
      "   545         1    1271193.3 1271193.3      1.0      model = YOLO(model=model_path)\n",
      "   546                                           \n",
      "   547         1         15.4     15.4      0.0      video_dir, video_name = os.path.split(video_path)\n",
      "   548         1          0.6      0.6      0.0      video_dir = video_dir or os.getcwd()\n",
      "   549                                               \n",
      "   550         1          0.6      0.6      0.0      if not video_name:\n",
      "   551                                                   print(\"error no video name\")\n",
      "   552                                                   return\n",
      "   553         1         21.8     21.8      0.0      elif not os.path.exists(video_path):\n",
      "   554                                                   print(f\"video path {video_path} does not exist\")\n",
      "   555                                                   return\n",
      "   556                                           \n",
      "   557                                               # Open the video file\n",
      "   558         1      66994.4  66994.4      0.1      cap = FileVideoStream(path=video_path, queue_size=128, transform=None).start()\n",
      "   559                                           \n",
      "   560                                               # get the number of frames\n",
      "   561         1         27.6     27.6      0.0      video_frame_count = int(cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
      "   562                                               \n",
      "   563         1          3.3      3.3      0.0      original_width = cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
      "   564         1          1.6      1.6      0.0      original_height = cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
      "   565                                           \n",
      "   566         1          2.1      2.1      0.0      current_frame_num = 0\n",
      "   567         1          1.1      1.1      0.0      total_frame_num = (max_frames or video_frame_count)\n",
      "   568         1          0.8      0.8      0.0      if progress:\n",
      "   569         1        952.9    952.9      0.0          pbar = tqdm(total=total_frame_num)\n",
      "   570                                           \n",
      "   571                                               # Loop through the video frames\n",
      "   572       901     209893.9    233.0      0.2      while cap.more() and (current_frame_num < total_frame_num):\n",
      "   573       901      15265.4     16.9      0.0          frame = cap.read()\n",
      "   574                                                   \n",
      "   575       900        647.0      0.7      0.0          if frame is not None:\n",
      "   576       900        768.5      0.9      0.0              current_frame_num = current_frame_num + 1\n",
      "   577                                           \n",
      "   578       900      92294.0    102.5      0.1              slice_image_result = slice_image(\n",
      "   579       900        438.2      0.5      0.0                  image=frame,\n",
      "   580       900        693.9      0.8      0.0                  slice_height=640,\n",
      "   581       900        545.8      0.6      0.0                  slice_width=640,\n",
      "   582       900        574.0      0.6      0.0                  overlap_height_ratio=0.2,\n",
      "   583       900        626.9      0.7      0.0                  overlap_width_ratio=0.2,\n",
      "   584       900        525.4      0.6      0.0                  auto_slice_resolution=True,\n",
      "   585                                                       )\n",
      "   586                                           \n",
      "   587       899        726.4      0.8      0.0              if current_frame_num == 1: \n",
      "   588         1         16.3     16.3      0.0                  print(f\"type: {type(slice_image_result.images)}\")\n",
      "   589                                           \n",
      "   590       900  124888144.3 138764.6     98.5              model.predict(source=slice_image_result.images, device=\"cuda:0\", conf=0.5, verbose=False)\n",
      "   591                                           \n",
      "   592       900       1006.3      1.1      0.0              if progress:\n",
      "   593       900     213012.6    236.7      0.2                  pbar.update(1)\n",
      "   594                                           \n",
      "   595         1          2.5      2.5      0.0      if cap.running():\n",
      "   596                                                   cap.stop()\n",
      "   597                                                   \n",
      "   598         1          0.5      0.5      0.0      del frame\n",
      "   599         1          5.0      5.0      0.0      del cap.Q\n",
      "   600         1         35.7     35.7      0.0      del cap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_function_name=\"run_three\"\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\", \"samples/sample-Copy3.mp4\", \"samples/sample-Copy4.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=run_function_name\n",
    ")\n",
    "\n",
    "command = f\"python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_{run_function_name}.lprof\"\n",
    "\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87d6569-b53a-42d2-810b-f4492a3239fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:56:36.130936Z",
     "iopub.status.busy": "2023-11-17T06:56:36.130294Z",
     "iopub.status.idle": "2023-11-17T06:56:51.367313Z",
     "shell.execute_reply": "2023-11-17T06:56:51.366471Z",
     "shell.execute_reply.started": "2023-11-17T06:56:36.130912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/906 [00:08<05:11,  2.86it/s]Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbenchmarking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_multi\n\u001b[1;32m      9\u001b[0m run_function_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_four\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mrun_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msamples/sample-Copy1.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msamples/sample-Copy2.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msamples/sample-Copy3.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msamples/sample-Copy4.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_function_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_function_name\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_function_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.lprof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$command\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/benchmarking.py:960\u001b[0m, in \u001b[0;36mrun_multi\u001b[0;34m(video_list, model_path, max_frames, profile, progress, run_function_name)\u001b[0m\n\u001b[1;32m    957\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;66;03m# Retrieve the results\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     output \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/notebooks/benchmarking.py:960\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    957\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;66;03m# Retrieve the results\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     output \u001b[38;5;241m=\u001b[39m [\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_function_name=\"run_four\"\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\", \"samples/sample-Copy3.mp4\", \"samples/sample-Copy4.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=run_function_name\n",
    ")\n",
    "\n",
    "command = f\"python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_{run_function_name}.lprof\"\n",
    "\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66eadc15-d71f-4662-9905-6e4464e0c169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T03:04:57.445812Z",
     "iopub.status.busy": "2023-11-17T03:04:57.445560Z",
     "iopub.status.idle": "2023-11-17T03:09:22.371119Z",
     "shell.execute_reply": "2023-11-17T03:09:22.370164Z",
     "shell.execute_reply.started": "2023-11-17T03:04:57.445792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 900/906 [04:17<00:01,  3.50it/s]\n",
      " 99%|█████████▉| 900/906 [04:17<00:01,  3.50it/s]\n",
      " 99%|█████████▉| 900/906 [04:17<00:01,  3.49it/s]\n",
      " 99%|█████████▉| 900/906 [04:18<00:01,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/__main__.py\", line 4, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/line_profiler.py\", line 324, in main\n",
      "    lstats = load_stats(args.profile_output)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/line_profiler/line_profiler.py\", line 295, in load_stats\n",
      "    with open(filename, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/notebooks/profile_run_sample-Copy1.mp4_.lprof'\n"
     ]
    }
   ],
   "source": [
    "from artifacts import download_artifact\n",
    "\n",
    "artifact, artifact_location = download_artifact(\"vacocam_model\")\n",
    "\n",
    "model_path = f\"{artifact_location}/best.pt\"\n",
    "\n",
    "from benchmarking import run_multi\n",
    "\n",
    "run_function_name=\"run_five\"\n",
    "\n",
    "run_multi(\n",
    "    [\"samples/sample-Copy1.mp4\",\"samples/sample-Copy2.mp4\", \"samples/sample-Copy3.mp4\", \"samples/sample-Copy4.mp4\"],\n",
    "    model_path,\n",
    "    profile=True,\n",
    "    progress=True,\n",
    "    run_function_name=run_function_name\n",
    ")\n",
    "\n",
    "command = f\"python -m line_profiler /notebooks/profile_run_sample-Copy1.mp4_{run_function_name}.lprof\"\n",
    "\n",
    "!$command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
